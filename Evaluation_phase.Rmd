---
title: "Evaluation phase"
output: html_document
---

In this phase, we are going to summarize all the results we found from the different classifications algorithms

# Evaluation

```{r}
library(tidyverse)
library(data.table)
library(dplyr)
library(formattable)
library(tidyr)
source("./tools/data_visualization_functions.R")
```

We import all the results
```{r}
decision_tree_results <- read.csv2("./dataset/results/decision_tree.csv", sep=";", dec=",")
logistic_regression_results <- read.csv2("./dataset/results/logistic_regression.csv", sep=";", dec=",")
knn_results<- read.csv2("./dataset/results/knn.csv", sep=";", dec=",")
naive_bayes_classifier_results<- read.csv2("./dataset/results/naive_bayes_classifier.csv", sep=";", dec=",")
random_forest_results<- read.csv2("./dataset/results/random_forest.csv", sep=";", dec=",")

support_vector_machines_results<- read.csv2("./dataset/results/support_vector_machines.csv", sep=";", dec=",")
neural_network_results<- read.csv2("./dataset/results/neural_network.csv", sep=";", dec=",")
```


```{r}
logistic_regression_results <- logistic_regression_results[, 2:2]
knn_results <- knn_results[, 2:2]
naive_bayes_classifier_results <- naive_bayes_classifier_results[, 2:2]
random_forest_results <- random_forest_results[, 2:2]
support_vector_machines_results <- support_vector_machines_results[, 2:2]
neural_network_results <- neural_network_results[, 2:2]


table <- cbind(decision_tree_results,
               logistic_regression_results,
               knn_results,
               naive_bayes_classifier_results,
               random_forest_results,
               support_vector_machines_results,
               neural_network_results)
```


```{r}
customRed0 = "#fff0f0"
customRed1 = "#ff7575"
```


```{r}
formattable(table,
            align =c("l","c","c","c","c", "c"),
            list(`Indicator Name` = formatter("span", style = ~ style(color = "grey", font.weight = "bold")), 
                 `decision_tree_results`= color_tile(customRed0, customRed1),
                 `logistic_regression_results`= color_tile(customRed0, customRed1),
                 `knn_results`= color_tile(customRed0, customRed1),
                 `naive_bayes_classifier_results`= color_tile(customRed0, customRed1),
                 `random_forest_results`= color_tile(customRed0, customRed1),
                 `support_vector_machines_results`= color_tile(customRed0, customRed1),
                 `neural_network_results`= color_tile(customRed0, customRed1)
))
```

As we can see, in general, when we apply the z-normalization and the z-log normalization, we have better accuracy than without them. It's even more flagrant, when doing the k-fold cross validation.

However, using the neural network is more difficult. I have used various parameters to try to have better performance, but this is the best I could get (for the last one, the accuracy is 0.0, because I kept getting error each time running it). I think it's due to the small amount of data in the data set. Usually for better performance with neural network, much more data are needed.

```{r}
# We plot the boxplot of the accuracy with the k-fold cross validation
draw_boxplot(tail(table[ ,2:ncol(table)], 3))
```

```{r}
# We plot the boxplot of the accuracy with the k-fold cross validation (without neural network)
draw_boxplot(tail(table[ ,2:ncol(table)-1], 3))
```


If we would have to choose which is the best model to continue with this project, we should choose the support vector machines, because as we can see on this boxplot, it leads to the best overall accuracy on the k-fold cross validation.


# Conclusion
In conclusion, applying the z-normalization and the z-score normalization is helpful to improve the accuracy of our classification algorithms. However the gain of applying the normalization is not very much, it is at most 2% more than without the normalization (k-fold cross validation). Even sometimes, applying the z-normalization or the z-log normalization do not always lead to better accuracy (e.g. Decsion tree).
The problem of these normalizations is that they are highly dependent on the estimation of the reference intervals. Different estimations, can lead to different results.
